{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Linear regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create model, compute loss, and optimize the parameters  \n",
    "\n",
    "1. 所有的层结构和损失函数，都来自torch.nn；因此，所有的模型构建都是从nn.Module继承的。  \n",
    "2. torch.optim，通过修改参数，使得loss function最小化。  \n",
    "    一阶优化算法：  \n",
    "    $$\\theta = \\theta - \\eta * \\frac {\\partial J(\\theta)}{\\partial \\theta}$$  \n",
    "    $\\eta $ is learning rate. $\\frac {\\partial J(\\theta)}{\\partial \\theta}$ is the gradient of the function J.  \n",
    "   We can use torch.optim:   \n",
    "   e.g optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)   \n",
    "3. torch.save \n",
    "    1. save the constructure of the model and parameters---save model.  \n",
    "      torch.save(model, './model.pth')\n",
    "    \n",
    "    2. save the states of the model.  \n",
    "      torch.save(model.state_dict(), './model_state.pth'  \n",
    "\n",
    "4. torch.load\n",
    "    1. load the constructure of the model and parameters.   \n",
    "         load_model = torch.load('model.pth')\n",
    "     \n",
    "    2. load the states of the model.   \n",
    "         load_model = model.load_state_dic(torch.load('model_state.pth')\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3000],\n",
      "        [3.3000],\n",
      "        [4.4000],\n",
      "        [5.5000],\n",
      "        [6.7000],\n",
      "        [3.1000]])\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[2.3],[3.3],[4.4],[5.5],[6.7],[3.1]], dtype=np.float32)\n",
    "y = np.array([[0.9],[1.7],[2.76],[2.09],[3.19],[1.3]], dtype=np.float32)\n",
    "\n",
    "# convert numpy to tensor\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.Linear = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.Linear(x)\n",
    "        return output\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = LinearRegression().cuda()\n",
    "else:\n",
    "    model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "critirion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.13792981207370758\n",
      "loss is 0.1377684623003006\n",
      "loss is 0.137613907456398\n",
      "loss is 0.13746599853038788\n",
      "loss is 0.13732431828975677\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for i in range(500):\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(x).cuda()\n",
    "        target = Variable(y).cuda()\n",
    "    else:\n",
    "        inputs = Variable(x)\n",
    "        target = Variable(y)\n",
    "    output = model(inputs)\n",
    "    loss = critirion(output, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1)%100 == 0:\n",
    "        print('loss is {}'.format(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "predict = model(Variable(x))\n",
    "# 将预测值画出来\n",
    "predict = predict.data.numpy()\n",
    "plt.plot(x.numpy(), y.numpy(),'ro', label='original data')\n",
    "plt.plot(x.numpy(), predict, label='Fitting Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.array 转换成Tensor：torch.from_numpy(x_numpy)   \n",
    "model.cuda(): 将模型放到GPU上    \n",
    "每次做反向传播之前，都要做归零梯度：optimizer.zero_grad()  \n",
    "model.eval(): 将模型变成测试模式； 这是因为有一些层操作，比如dropout 和 BatchNormalization 在 __训练__和 __测试__ 时不一样。  \n",
    "定义的模型是线性的，所以，在这里，模型预测的值，画出来就是一条直线。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多项式回归\n",
    "$$ y = b + w1*x + w2*x^2 + w3*x^3$$\n",
    "$$ y = 0.9 + 0.5*x + 3*x^2 + 2.4*x^3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define w, b, x\n",
    "w = torch.FloatTensor([0.5, 3, 2.4]).unsqueeze(1)     ## unsqueeze(1):将原来的tensor大小由3变成（3，1）。\n",
    "b = torch.FloatTensor([0.9])\n",
    "\n",
    "def make_features(x):\n",
    "    x = x.unsqueeze(1)\n",
    "    return torch.cat([x**i for i in range(1, 4)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "def f(x):\n",
    "    return x.mm(w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=32):\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    if torch.cuda.is_available():\n",
    "        return Variable(x).cuda(), Variable(y).cuda()\n",
    "    else:\n",
    "        return Variable(x), Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class poly_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(poly_model, self).__init__()\n",
    "        self.poly = nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.poly(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.2787, grad_fn=<MseLossBackward>)\n",
      "tensor(18.1711, grad_fn=<MseLossBackward>)\n",
      "tensor(189.5407, grad_fn=<MseLossBackward>)\n",
      "tensor(31.1954, grad_fn=<MseLossBackward>)\n",
      "tensor(27.0076, grad_fn=<MseLossBackward>)\n",
      "tensor(9.9079, grad_fn=<MseLossBackward>)\n",
      "tensor(40.8867, grad_fn=<MseLossBackward>)\n",
      "tensor(170.2798, grad_fn=<MseLossBackward>)\n",
      "tensor(217.1426, grad_fn=<MseLossBackward>)\n",
      "tensor(16.5302, grad_fn=<MseLossBackward>)\n",
      "tensor(21.0001, grad_fn=<MseLossBackward>)\n",
      "tensor(31.7558, grad_fn=<MseLossBackward>)\n",
      "tensor(47.3486, grad_fn=<MseLossBackward>)\n",
      "tensor(36.7145, grad_fn=<MseLossBackward>)\n",
      "tensor(78.0644, grad_fn=<MseLossBackward>)\n",
      "tensor(44.4921, grad_fn=<MseLossBackward>)\n",
      "tensor(47.6174, grad_fn=<MseLossBackward>)\n",
      "tensor(89.8377, grad_fn=<MseLossBackward>)\n",
      "tensor(14.7957, grad_fn=<MseLossBackward>)\n",
      "tensor(65.5730, grad_fn=<MseLossBackward>)\n",
      "tensor(54.5707, grad_fn=<MseLossBackward>)\n",
      "tensor(103.0809, grad_fn=<MseLossBackward>)\n",
      "tensor(20.2904, grad_fn=<MseLossBackward>)\n",
      "tensor(110.7438, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7854, grad_fn=<MseLossBackward>)\n",
      "tensor(10.5594, grad_fn=<MseLossBackward>)\n",
      "tensor(21.5078, grad_fn=<MseLossBackward>)\n",
      "tensor(27.9956, grad_fn=<MseLossBackward>)\n",
      "tensor(86.6094, grad_fn=<MseLossBackward>)\n",
      "tensor(46.6326, grad_fn=<MseLossBackward>)\n",
      "tensor(13.2368, grad_fn=<MseLossBackward>)\n",
      "tensor(45.8326, grad_fn=<MseLossBackward>)\n",
      "tensor(30.2203, grad_fn=<MseLossBackward>)\n",
      "tensor(29.5153, grad_fn=<MseLossBackward>)\n",
      "tensor(7.4682, grad_fn=<MseLossBackward>)\n",
      "tensor(9.4883, grad_fn=<MseLossBackward>)\n",
      "tensor(88.0134, grad_fn=<MseLossBackward>)\n",
      "tensor(27.4339, grad_fn=<MseLossBackward>)\n",
      "tensor(8.5999, grad_fn=<MseLossBackward>)\n",
      "tensor(21.7406, grad_fn=<MseLossBackward>)\n",
      "tensor(40.8535, grad_fn=<MseLossBackward>)\n",
      "tensor(79.4400, grad_fn=<MseLossBackward>)\n",
      "tensor(24.9007, grad_fn=<MseLossBackward>)\n",
      "tensor(44.1767, grad_fn=<MseLossBackward>)\n",
      "tensor(18.4430, grad_fn=<MseLossBackward>)\n",
      "tensor(22.8686, grad_fn=<MseLossBackward>)\n",
      "tensor(23.5184, grad_fn=<MseLossBackward>)\n",
      "tensor(17.7993, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5524, grad_fn=<MseLossBackward>)\n",
      "tensor(16.0731, grad_fn=<MseLossBackward>)\n",
      "tensor(28.0901, grad_fn=<MseLossBackward>)\n",
      "tensor(38.3090, grad_fn=<MseLossBackward>)\n",
      "tensor(5.7332, grad_fn=<MseLossBackward>)\n",
      "tensor(9.9886, grad_fn=<MseLossBackward>)\n",
      "tensor(11.8823, grad_fn=<MseLossBackward>)\n",
      "tensor(15.4665, grad_fn=<MseLossBackward>)\n",
      "tensor(11.9326, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1076, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1716, grad_fn=<MseLossBackward>)\n",
      "tensor(13.3389, grad_fn=<MseLossBackward>)\n",
      "tensor(12.1987, grad_fn=<MseLossBackward>)\n",
      "tensor(20.7552, grad_fn=<MseLossBackward>)\n",
      "tensor(10.3605, grad_fn=<MseLossBackward>)\n",
      "tensor(13.7655, grad_fn=<MseLossBackward>)\n",
      "tensor(24.2205, grad_fn=<MseLossBackward>)\n",
      "tensor(13.5638, grad_fn=<MseLossBackward>)\n",
      "tensor(6.9819, grad_fn=<MseLossBackward>)\n",
      "tensor(26.4143, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0549, grad_fn=<MseLossBackward>)\n",
      "tensor(29.6922, grad_fn=<MseLossBackward>)\n",
      "tensor(25.5039, grad_fn=<MseLossBackward>)\n",
      "tensor(13.7663, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0371, grad_fn=<MseLossBackward>)\n",
      "tensor(10.6925, grad_fn=<MseLossBackward>)\n",
      "tensor(8.7659, grad_fn=<MseLossBackward>)\n",
      "tensor(14.1517, grad_fn=<MseLossBackward>)\n",
      "tensor(28.3171, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5172, grad_fn=<MseLossBackward>)\n",
      "tensor(9.1305, grad_fn=<MseLossBackward>)\n",
      "tensor(10.9427, grad_fn=<MseLossBackward>)\n",
      "tensor(9.3276, grad_fn=<MseLossBackward>)\n",
      "tensor(23.1842, grad_fn=<MseLossBackward>)\n",
      "tensor(8.0897, grad_fn=<MseLossBackward>)\n",
      "tensor(8.4544, grad_fn=<MseLossBackward>)\n",
      "tensor(23.3728, grad_fn=<MseLossBackward>)\n",
      "tensor(13.5134, grad_fn=<MseLossBackward>)\n",
      "tensor(9.5345, grad_fn=<MseLossBackward>)\n",
      "tensor(44.2208, grad_fn=<MseLossBackward>)\n",
      "tensor(8.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(5.6813, grad_fn=<MseLossBackward>)\n",
      "tensor(11.7775, grad_fn=<MseLossBackward>)\n",
      "tensor(21.4100, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9090, grad_fn=<MseLossBackward>)\n",
      "tensor(18.0682, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0828, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1822, grad_fn=<MseLossBackward>)\n",
      "tensor(4.3765, grad_fn=<MseLossBackward>)\n",
      "tensor(4.5310, grad_fn=<MseLossBackward>)\n",
      "tensor(13.0701, grad_fn=<MseLossBackward>)\n",
      "tensor(13.6468, grad_fn=<MseLossBackward>)\n",
      "tensor(10.4069, grad_fn=<MseLossBackward>)\n",
      "tensor(9.6474, grad_fn=<MseLossBackward>)\n",
      "tensor(7.0416, grad_fn=<MseLossBackward>)\n",
      "tensor(12.0762, grad_fn=<MseLossBackward>)\n",
      "tensor(12.2485, grad_fn=<MseLossBackward>)\n",
      "tensor(13.1209, grad_fn=<MseLossBackward>)\n",
      "tensor(12.8162, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5261, grad_fn=<MseLossBackward>)\n",
      "tensor(9.0279, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4901, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1120, grad_fn=<MseLossBackward>)\n",
      "tensor(6.2405, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5733, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9175, grad_fn=<MseLossBackward>)\n",
      "tensor(7.1253, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4098, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1939, grad_fn=<MseLossBackward>)\n",
      "tensor(7.3280, grad_fn=<MseLossBackward>)\n",
      "tensor(7.3282, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3383, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0557, grad_fn=<MseLossBackward>)\n",
      "tensor(11.7871, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0879, grad_fn=<MseLossBackward>)\n",
      "tensor(7.0693, grad_fn=<MseLossBackward>)\n",
      "tensor(7.9777, grad_fn=<MseLossBackward>)\n",
      "tensor(11.4204, grad_fn=<MseLossBackward>)\n",
      "tensor(5.2806, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2888, grad_fn=<MseLossBackward>)\n",
      "tensor(8.7033, grad_fn=<MseLossBackward>)\n",
      "tensor(7.6458, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6616, grad_fn=<MseLossBackward>)\n",
      "tensor(15.6958, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1462, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3213, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1319, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4190, grad_fn=<MseLossBackward>)\n",
      "tensor(5.2931, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1513, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6767, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6994, grad_fn=<MseLossBackward>)\n",
      "tensor(7.8071, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1124, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1587, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2617, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5416, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8712, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3399, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0553, grad_fn=<MseLossBackward>)\n",
      "tensor(9.8395, grad_fn=<MseLossBackward>)\n",
      "tensor(6.6292, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1338, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0607, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7774, grad_fn=<MseLossBackward>)\n",
      "tensor(9.4690, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3423, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0168, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8946, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6499, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1150, grad_fn=<MseLossBackward>)\n",
      "tensor(4.8924, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1765, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1457, grad_fn=<MseLossBackward>)\n",
      "tensor(5.3025, grad_fn=<MseLossBackward>)\n",
      "tensor(5.7573, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4400, grad_fn=<MseLossBackward>)\n",
      "tensor(4.9017, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1676, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3849, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1640, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7074, grad_fn=<MseLossBackward>)\n",
      "tensor(4.5676, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4097, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4661, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0842, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9286, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3827, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7172, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4856, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6438, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8999, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7575, grad_fn=<MseLossBackward>)\n",
      "tensor(5.9189, grad_fn=<MseLossBackward>)\n",
      "tensor(5.9319, grad_fn=<MseLossBackward>)\n",
      "tensor(8.4411, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0207, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4330, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6666, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1666, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5314, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3117, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0914, grad_fn=<MseLossBackward>)\n",
      "tensor(4.3463, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4885, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5719, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9567, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3954, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7953, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6301, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8647, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2142, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4140, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5677, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7120, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0316, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5099, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8234, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2549, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8670, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4138, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6618, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5960, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0641, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2165, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6800, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5742, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9542, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0935, grad_fn=<MseLossBackward>)\n",
      "tensor(5.2943, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4254, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1739, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9913, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2905, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4720, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1497, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8699, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1723, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0190, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3072, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7435, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0697, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9667, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3065, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2095, grad_fn=<MseLossBackward>)\n",
      "tensor(6.9659, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3638, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4188, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5571, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7778, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0624, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6858, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1942, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7977, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0408, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7620, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3093, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5396, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6494, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5406, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7596, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6711, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5852, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3849, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5784, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2954, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5651, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8249, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6991, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6341, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9899, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6093, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3768, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7536, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5774, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9944, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5969, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3229, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1629, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8479, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8798, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2095, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4860, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7628, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9455, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2941, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7683, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8456, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6076, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9260, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9464, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5812, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1787, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4856, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5891, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4522, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5460, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7190, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6226, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1166, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3085, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4990, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1431, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2670, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5968, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4391, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1177, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3522, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2906, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2209, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3545, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6385, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5541, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8766, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0399, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2748, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5261, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0130, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4599, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7198, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6760, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4873, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5195, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3202, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9249, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3763, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8438, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6803, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9240, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5305, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1712, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8332, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6203, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6571, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7721, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9159, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5712, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3446, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4230, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9782, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9943, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8889, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4291, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3580, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7918, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2308, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4697, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2297, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2813, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3371, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4210, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5589, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3088, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2672, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8117, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9827, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4795, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2903, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2591, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1197, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8678, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1472, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1740, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3690, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5489, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1290, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2138, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2519, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1954, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4416, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6115, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2667, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2127, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1640, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5845, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8773, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1157, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1491, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2811, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8343, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2976, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1937, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3840, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1932, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3385, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5560, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2278, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3265, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2139, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3427, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8631, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1113, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2468, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1351, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5694, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5574, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2286, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2498, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5407, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1885, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3902, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2212, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5825, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3724, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8756, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3165, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5509, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5131, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2745, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4306, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5779, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2998, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1472, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3190, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4647, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9529, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4943, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3993, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3433, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2368, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1789, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1953, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2340, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1584, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2719, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1561, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1337, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1348, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2848, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2473, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1222, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1661, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2496, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2558, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5828, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1608, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3669, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1609, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1474, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2765, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2858, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1385, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1930, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5157, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1548, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1905, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1803, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1470, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1468, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2313, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2472, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1862, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3562, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2355, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1952, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2886, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1390, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4629, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1944, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6137, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1939, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2857, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2738, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1394, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2146, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5336, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1633, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1480, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4718, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1498, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1942, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2821, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2549, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2560, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5636, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1566, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2671, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2272, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2508, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2616, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1488, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2760, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1825, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1769, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1769, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1369, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1781, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1454, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2590, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2128, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1642, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1884, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1503, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1197, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1286, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1552, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1161, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1900, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4447, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3203, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6611, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1662, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1255, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1908, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1903, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1806, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1471, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1603, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1454, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1150, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1340, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1599, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2057, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1965, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4809, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2175, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1325, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0928, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1071, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1355, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1590, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1337, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2495, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1780, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3368, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2394, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1151, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1212, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1257, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2155, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1241, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1315, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1761, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1974, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1573, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1429, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2691, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1195, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0918, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1260, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1232, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1575, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1109, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0969, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1562, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1972, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1678, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1144, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1479, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1199, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1458, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1078, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1308, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3440, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1638, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1545, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1480, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2283, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1924, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1219, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0834, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1193, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1689, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1356, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0967, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2129, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1130, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1282, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1221, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1085, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4933, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0905, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1218, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1305, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1394, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2796, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1097, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1078, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1222, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1111, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1125, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2360, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1300, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0901, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1604, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0969, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0866, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0918, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0858, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2136, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1184, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2865, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1428, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0930, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0851, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1570, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1527, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0914, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1319, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0891, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2561, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0991, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1709, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0802, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3496, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2243, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0978, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0949, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0909, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1121, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0872, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0900, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0915, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0941, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1190, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0812, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1167, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0918, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1362, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3249, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2524, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0920, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0867, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0691, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0934, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0871, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0868, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0985, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0892, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1861, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0879, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0947, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0955, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2050, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1816, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1516, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1596, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0996, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0945, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0767, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0977, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1105, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0910, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0854, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0829, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0739, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0778, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0990, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0901, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0769, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0830, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0695, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1111, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0860, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0906, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0671, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0743, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0850, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0958, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0879, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0904, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0982, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0885, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0730, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1232, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0813, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0855, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0797, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0716, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0799, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0648, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0920, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0829, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1128, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0703, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0971, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1338, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0896, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1192, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0837, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0791, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1347, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0854, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0710, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0682, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0694, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0855, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0757, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0817, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1211, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0836, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0769, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0718, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0955, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0877, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0861, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0767, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0792, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0606, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0760, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0764, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0905, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0971, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0840, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1211, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0799, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0886, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0532, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1527, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0697, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0792, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0623, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0711, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0773, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0628, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0887, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0873, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0743, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0848, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0701, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0613, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0717, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0721, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0745, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0739, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1117, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0804, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0728, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0662, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0704, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0594, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0857, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0787, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0661, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0780, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1063, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0939, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0440, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0882, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0833, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0762, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0566, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0473, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1761, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0665, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0803, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0923, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0692, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0764, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1156, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0675, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0482, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0590, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0918, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0625, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0655, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0521, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0870, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0817, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0678, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0590, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1112, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0563, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0671, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1181, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0605, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0717, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0665, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0710, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0681, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0694, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0537, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0448, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0461, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0733, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0483, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0632, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0543, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0477, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0679, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0994, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0634, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0643, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0734, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0551, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0586, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0631, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0643, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0537, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0538, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1350, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0658, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0664, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0584, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0614, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0499, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0428, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0487, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0489, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0536, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0591, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0410, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0538, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0459, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0531, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0522, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0817, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0544, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0903, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0483, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0768, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0483, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0897, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0445, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0503, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0448, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0719, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0493, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0533, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0456, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0574, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0411, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0487, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0520, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0858, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0549, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0577, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0703, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0530, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0491, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0800, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0418, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0445, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0657, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0540, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0489, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0453, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0646, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0452, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0566, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0404, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0560, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0412, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0527, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0497, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0447, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1107, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0521, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0380, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0332, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0532, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0616, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0421, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0529, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0488, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0933, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0412, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0484, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0464, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0391, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0734, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0469, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0450, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0663, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0413, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0441, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0503, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0668, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0441, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0487, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0452, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0458, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0417, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0501, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0399, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0391, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0409, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0391, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0475, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0523, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0417, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0525, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0371, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0457, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0525, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0431, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0577, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0400, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0455, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0370, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0393, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0424, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0383, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0454, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0385, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0361, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0395, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0366, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0464, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0473, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0363, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0392, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0372, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0331, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0459, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0358, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0586, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0411, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0454, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0598, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0474, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0355, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0476, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0460, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0594, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0460, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0393, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0395, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0448, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0328, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0469, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0634, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0459, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0425, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0472, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0470, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0335, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0393, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0343, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0373, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0358, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0362, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0366, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0338, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0311, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0499, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0313, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0485, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0315, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0404, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0403, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0414, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0319, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0342, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0344, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0307, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0345, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0326, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0469, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0349, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0335, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0332, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0261, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0561, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0341, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0303, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0361, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0354, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0277, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0299, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0297, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0426, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0336, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0408, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0367, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0423, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0445, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0372, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0357, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0347, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0373, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0300, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0346, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0713, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0342, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0403, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0376, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0301, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0497, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0407, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0755, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0330, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0299, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0347, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0331, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0307, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0364, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0240, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0281, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0428, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0375, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0297, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0328, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0312, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0354, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0264, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0314, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0299, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0440, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0387, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0220, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0301, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0282, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0322, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0309, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0309, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0272, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0256, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0314, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0348, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0703, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0237, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0314, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0479, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0277, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0336, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0531, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0264, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0338, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0311, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0468, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0302, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0317, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0315, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0422, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0334, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0457, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0321, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0335, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0237, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0264, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0278, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0272, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0354, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0341, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0252, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0231, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0388, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0228, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0495, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0229, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0216, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0221, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0378, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0277, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0277, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0232, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0211, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0260, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0336, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0256, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0199, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0241, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0221, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0237, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0237, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0319, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0217, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0218, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0187, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0218, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0180, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0456, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0183, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0229, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0275, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0161, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0187, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0167, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0221, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0145, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0168, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0168, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0168, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0174, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0219, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0211, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0118, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0124, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0181, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0115, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0145, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0111, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0127, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0124, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0125, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0132, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0132, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0127, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0107, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0118, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0107, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0331, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0113, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0115, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0132, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0125, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0108, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0093, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0115, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0108, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0124, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0093, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0063, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0108, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Compare the f(x) and the class poly_model, then compute the loss\n",
    "# define the model\n",
    "if torch.cuda.is_available():\n",
    "    model = poly_model().cuda()\n",
    "else:\n",
    "    model = poly_model()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "epoch = 0 \n",
    "while True:\n",
    "    batch_x, batch_y = get_batch()\n",
    "    out = model(batch_x)\n",
    "    loss = criterion(out, batch_y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch += 1\n",
    "    if (epoch+1)%10000:\n",
    "        print(loss)\n",
    "    if loss < 1e-3:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyx = np.arange(-1, 1, 0.25, dtype='float32')  ### here dtype='float32' is important.\n",
    "x = torch.from_numpy(numpyx)\n",
    "x = make_features(x)\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12693a090>,\n",
       " <matplotlib.lines.Line2D at 0x126942a10>,\n",
       " <matplotlib.lines.Line2D at 0x12694c610>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV5Z348c+TfQeyhyUJEPYdI6CoRVFBULRqW6duXenU7tv86uBYdcaZdjrTTltbFWtHHbHagAuLoqhQhSAQtrCEhABJgJt933OX5/fHuYGbkOUm9+TeLN/365VX7j3n3O/55uTmm3Of5znnUVprhBBCDH1+vk5ACCGEOaSgCyHEMCEFXQghhgkp6EIIMUxIQRdCiGEiwFc7jo2N1ampqb7avRBCDEkHDx6s0FrHdbXOZwU9NTWVrKwsX+1eCCGGJKVUYXfrpMlFCCGGCSnoQggxTEhBF0KIYUIKuhBCDBNS0IUQYpiQgi6EEMOE2wVdKeWvlDqslNraxbpgpdQbSql8pdQ+pVSqmUkKIYToXV/O0H8A5HSz7utAtdY6Dfgt8CtPExNC+MCGDTz/0FQOzIiA1FTYsMGUmCwZB9cGw+QUc2K6sc//uuO7ZE2YZd7PMQS4VdCVUuOB1cCfu9nkTuBl5+ONwHKllPI8PSGE12zYgOXnj/DHG4PYNyMcCgth7VrPiuGGDUaMtBpYEgQFRZ7HdGOfZ//pFzwz6zaOJE4x5+cYItw9Q/8f4J8ARzfrxwHnAbTWNqAWiOm8kVJqrVIqSymVVV5e3o90hRADZt06Ni0KQQH3/L3aWNbUBOvWeRST0BZIC4CsNqOCeBrTjX1uS0kHYHXubmPZQO9zkOi1oCulbgfKtNYHe9qsi2VXTIWktV6vtU7XWqfHxXV5KwIhhI9YLxbx1vVjuC67nqQq6+UVRUX9D1pUBFcHgk3DQZNiurHPbdOvI/3CCZLqK72zz0HCnTP0pcAapVQB8Dpwk1Lq1U7bXAAmACilAoBRQJWJeQohBtgnyydRPiaQL+yq7rgiObn/QSdNgHlBcMIKTS7neJ7E7EX+7Ks5FT+R23M+7bhiAPc5WPRa0LXWj2qtx2utU4H7gI+11g902mwz8LDz8b3ObWSyUiGGkIwvzyS+2sZ12fWXF4aFwdNP9z/oj1ZCiIIDLmfnnsbsxZav/BNKO7gtL9Nr+xws+j0OXSn1lFJqjfPpi0CMUiof+DHwczOSE0J4x4X6C2TqAu6J/hwBE1JAKUhJgfXr4f77+xdUa+AIBCdDwDhzYva6S802YlkU4SAhJtIr+xxM+nT7XK31LmCX8/HjLstbgC+YmZgQwnvePP0mSinuvucJeOg5c4Ke+wTKT8Fdz8Gj/2BOzF7kltaTX9bAw3fOg38p8Mo+BxO5UlSIEc7qsPJW/lvcMO4GEsMTzQu8fz2ExcCsz5sXsxfbsovxU7BydpLX9jmYSEEXYoTbdX4XFc0V3Dv1XvOC1pyH3Hdh4cMQGGJe3B5ordmaXcw1k2OIiwz2yj4HGynoQoxwGbkZJIYnct2468wLmvUX43v618yL2YuTxXWcq2hk9ZyxXtvnYCMFXYgR7Hz9efYW7+XuKXfj7+dvTlBrCxx6GaatgtETzInphq3Zxfj7KVbONrHZaIiRgi7ECLYpbxP+yp+70+42L+iJN6GpEhZ/y7yYvdBasy27mGsnxxAdHuS1/Q42UtCFGKGsdmdn6PgbSAhPMCeo1rDveYibDqnXmxPTDccu1lJU1cQdc0ducwtIQRdixPr4/MdUtVSZ2xl68SAUH4FF3zTGgHvJ1uxiAvwUt84y6R/TECUFXYgRKiMvg6TwJJaOXWpe0P3rITgK5t5nXsxetDe3XD8lltFhI7e5BaSgCzEiFdUVsa94H/dMuce8ztCGMjj+Jsz/MgRHmBPTDYfP13CxppnVI7y5BaSgCzEibTy9EX/lz+enmHjRz8GXwWGFq79pXkw3bMsuJsjfb8Q3t4AUdCFGHKvdyjv577BswjLiw+LNCWq3GmPPJy+H2DRzYrrB4TCaW26YGkdUSKDX9jtYSUEXYoT5qOgj8ztDT22DegssWmteTDccKqqmpK6F2+eOzEv9O5OCLsQIk5GXwbiIcVw79lrzgu5/AUanwJRbzIvphq3ZxQQF+HHzTGluASnoQowoBbUF7C/Zzz1T7sFPmfTnX3IcCnfD1d8AszpY3WB3aLYdK+bGaXFEBPfpxrHDlhR0IUaQTac3EaACzO0MPfACBITCgs7z3gysAwVVlNe3cruMbrlECroQI0Sbve1SZ2hsaKw5QZurIftvMPcLEBZtTkw3bc22EBLox03TTerYHQakoAsxQnxY+CHVrdV8YaqJc9EceQ2sTV4fqmizO9h+vITl0xMIl+aWS6SgCzFCbDy9kfER41kydok5AR0OozM0+RpImmtOTDftO1dFRUObjG7pRAq6ECPAudpzHCg5wD1TTewMzf8Qqs8Z923xsq3ZxYQF+bNsmjS3uJKCLsQIsDFvIwEqgLvS7jIv6P71EJEIM9b0vq2JrHYH248Xc/OMBEKDvDeqZiiQgi7EMNdqb+WdM+9wY/KN5nWGVp6B/B3GjET+3r1Cc++ZSqqbrKyW5pYrSEEXYpjbUbiD2tZacztDD7wIfoFw1VfMi+mmrdkWIoID+NzUOK/ve7DrtaArpUKUUvuVUkeVUieUUk92sc1XlFLlSqkjzq9vDEy6Qoi+2pi3kQmRE1ictNicgG2NcPhVmHknRHr3Cs02mzG65ZaZCYQESnNLZ+6M92kFbtJaNyilAoHdSqn3tNafddruDa31d81PUQjRX2drznKw9CA/uupH5nWGZr8BrbVev28LwJ78CupabDK6pRu9FnSttQYanE8DnV96IJMSQpgjIy+DAL8A7px8pzkBtTaGKibNgwmLzInZB1uyLUSGBHDdFJP6AoYZt/5lK6X8lVJHgDJgh9Z6Xxeb3aOUylZKbVRKeW+qbyFEl1psLWw+s5nlycuJCY0xJ2jhHig7aZyde3GKOYBWm50dJ0pZMSuR4ABpbumKWwVda23XWs8HxgOLlFKzO22yBUjVWs8FPgRe7iqOUmqtUipLKZVVXl7uSd5CiF7sKNxBXVuduZ2h+9dD6BiYfY95Md30SV4F9a3S3NKTPjWqaa1rgF3Ayk7LK7XWrc6nLwBXdfP69VrrdK11elyc9FALMZA25m0kJSqFRYkmNY3UXoScrbDwIQgMNSdmH2zLtjA6LJCladLc0h13RrnEKaVGOx+HAjcDpzpt4/ovcw2QY2aSQoi+ya/O51DZIe6dci/KrKaRrL8AGtK/bk68Pmix2tlxspSVsxIJ9JfR1t1xZ5RLEvCyUsof4x/A37TWW5VSTwFZWuvNwPeVUmsAG1AFfGWgEhZC9G7j6Y0E+gWyJs2kqzhtrXDwJZh6G4xJMSdmH+zKLaexzS4XE/XCnVEu2cCCLpY/7vL4UeBRc1MTQvRHe2fozck3Ex1i0i1tT7wNTRU+uW8LGBcTRYcHcc0kkzp3hyn57CLEMPN+wfvUt9XzhWkmd4bGTIFJy8yL6aamNhsf5ZSxcnYiAdLc0iM5OkIMMxvzNpIalUp6Qro5AS8ehItZPhmqCLDzVDnNVruMbnGDFHQhhpHT1ac5Un6Ee6ea2Bm6/wUIioB595kTr4+2ZluIjQhm8URpbumNFHQhhpGMvAyjM3SySZ2hjRVwfBPM/zKERJkTsy+7b7Xx8akyVs1JxN/P+58Ohhop6EIME822Zrae2cotKbcwJmSMOUEPvQz2Nq9PMdfuw5xSWm0OmQjaTVLQhRgmtp/bTr213rwrQ+02OPAXoyM0bqo5MftoW3YxCVHBpKeY9A9qmJOCLsQwsfH0RiaNmsRVCV1eqN13ee9B3QWf3FURoL7Fyq68clbNScJPmlvcIgVdiGEgtyqX7PJscztD9z0Po5Jh6sretx0AO06W0mZzyOiWPpCCLsQwkJGXQZBfkHmdoWU5UPApXP118PPNnQ23ZRczdlQICyZIc4u7pKALMcQ1WZvYdnYbt6beyqjgUeYE3f8CBIQYN+LygdomK5+cluaWvpKCLsQQt71gOw3WBvM6Q1tq4ejrMPteCDPp1gF99MHJEqx2ze3zZHRLX0hBF2KI25i3kcmjJrMg/opbLvXPkdfA2uiz+7YAbM0uZvyYUOaNN+kTxwghBV2IIexU1SmOVRzjC9O+YE5nqMNhNLeMXwRj53serx+qG9vYk1/B6rlJ5nXwjhBS0IUYwjJyMwj2D+b2SbebE/Dsx1B1BhZ/y5x4/fD+iRJsDs0dcjFRn0lBF2KIarI2se3cNlakrjC3MzQ8HmaYNFqmH7YdKyYlJoxZY71/q4GhTgq6EEPUu+fepdHaaF5naNU5yHsf0r8KAUHmxOyjyoZWMs9Ucrs0t/SLFHQhhqiNeRtJG53GvLh55gQ88GdjzPlVXzUnXj+8d7wEu0Ozeo40t/SHFHQhhqCTlSc5UXnCvCtD25rg8P/BjDsgyndXZm7LLmZSXDgzkiJ9lsNQJgVdiCEoIy+DEP8Q7ph8hzkBj2UY488X+a4ztKy+hX3nKrl9jjS39JcUdCGGmEZrI++efZcVqSuICjKh41BrozM0YQ4kL/E8Xj9tP16CQyMXE3lACroQQ8y2s9tosjWZN2do0WdQesy4kMiHZ8ZbjxYzJT6CqQnS3NJfUtCFGGI25m1k6pipzI2da07A/c9DyCiYY+Kk0n1UUtvCgcIqmcjCQ1LQhRhCTlScIKcqx7zO0DoL5GyBBQ9CUJjn8frp3WPFaA2r5Va5Hum1oCulQpRS+5VSR5VSJ5RST3axTbBS6g2lVL5Sap9SKnUgkhVipMvIyyA0INS8K0MPvgQOO1z9DXPi9dPWbAvTEyNJi4/waR5DnTtn6K3ATVrrecB8YKVSqnPPydeBaq11GvBb4FfmpimEaGhr4N1z77IydSWRQSa0M9vaIOt/YeoKiJ7oebx+uljTzKGiGu6QzlCP9VrQtaHB+TTQ+aU7bXYn8LLz8UZguZJxR0KYatvZbTTbms27MjRnMzSW+fSuigDvZhcDsHqONLd4yq02dKWUv1LqCFAG7NBa7+u0yTjgPIDW2gbUAjFdxFmrlMpSSmWVl5d7lrkQI4jWmoy8DKZHT2d27Gxzgu57HqInw6SbzInXT1uPFTN7XBSpseE+zWM4cKuga63tWuv5wHhgkVKq8zuqq7PxzmfxaK3Xa63TtdbpcXFxfc9WiBHqeMVxcqtzuXeKSZ2hlsNwYb9xdu7nu7ER56uaOHq+Ri71N0mffpNa6xpgF9B51tgLwAQApVQAMAqoMiE/IQSXO0NXT1ptTsD9f4bAcJj/ZXPi9dO2Y0Zzi0wEbQ53RrnEKaVGOx+HAjcDpzptthl42Pn4XuBjrfUVZ+hCiL6rb6tne8F2Vk1cRUSQCaNAmqqMS/3n3WeMP/ehrdkW5o0fxYRo3w2ZHE7cOUNPAnYqpbKBAxht6FuVUk8ppdpvmvwiEKOUygd+DPx8YNIVYuQxvTP00Ctgb/V5Z2hBRSPHL9bJxUQmCuhtA611NnDFZIVa68ddHrcAvrvMTIhhqr0zdEb0DGbGzPQ8oMMOB16E1Oshfobn8TzQ3tyySppbTCNXigoxiGVXZJNXnWfelaF526G2CBat9TyWh7YctbAweTTjRof6OpVhQwq6EINYRm4GYQFhJnaGroeo8TBtlTnx+im/rIFTJfXS3GIyKehCDFJ1bXW8X/A+qyatIjzQhDHa5blwdhdc/TXw77W1dUBtyy5GKVglFxOZSgq6EIPU1jNbabG3mNcZeuDP4B8ECx/ufdsBtu2YhatTokkcFeLrVIYVKehCDELtnaEzY2aa0xnaUgdHXoPZ90B4rOfxPJBXWk9eaYPcWXEASEEXYhA6Wn6U/Jp8887Oj74ObQ0+H6oIsDW7GD8Ft81J9HUqw44UdCEGoYy8DMIDw1k10YTOS62NztBx6TDuKs/jeZSKZmu2hcUTY4iPlOYWs0lBF2KQqW2t5f2C91k9cTVhgSZcQXl2F1SeHhRDFXOK6zlb3ijNLQNECroQg8zWs1tptbeaN2fo/hcgLBZm3WVOPA9sO2YxmltmS3PLQJCCLsQgorUmIzeD2TGzmR493fOA1YWQ9x5c9RUICPY8ngeM5pZirp0cS0yEb3MZrqSgCzGIHC47zJnaM+adnWe9CChI/5o58TxwwlJHYWWT3FlxAElBF2IQycjLICIwgpWpne9Q3Q/WZuNGXDNuh1HjPI/noS3ZFgL8FCtmSXPLQJGCLsQgUdNSwwcFH7B6kkmdocc3QXP1oOgM1VqzLbuYpWmxjAkP8nU6w5YUdCEGiS1nt9DmaDNn7LnWxhRz8TMhZann8Tx09EItF6qbZXTLAJOCLsQg0H5l6NzYuUyLnuZ5wPP7oSTbuJBoEMzXvi3bQqC/YsVMaW4ZSFLQhRgEDpYe5FztOe6deq85Afevh+BRMOeL5sTzgMNhNLfcMCWOUWGBvk5nWJOCLsQgkJGXQWRgJCsnmtAZWl8CJ9+GBQ9AsAlT1nno8PlqLLUt0tziBVLQhfCx6pZqdhTu4PbJtxMaYMJkDwdfBocNrv6657FMsDW7mKAAP26ZmeDrVIY9KehC+NjmM5uxOqzmNLfYrZD1F0i7BWImex7PQw6H5t1jxXxuahyRIdLcMtCkoAvhQ1prNuZtZF7cPKaOmep5wJzN0FAyKIYqAmQVVlNa1yoXE3mJFHQhfCirNIuCugLzbpO7/wUYMxHSbjYnnoe2ZlsIDvBj+QxpbvEGKehC+FBGbgaRQZGsSF3hebDibCjaawxV9PP9n7bdoXn3WAk3TY8nIti3U96NFL7/rQsxQlW1VLGjaAdrJq8hJMCEe4MfeAECw2D+lz2PZYJ95yqpaGiV0S1e1GtBV0pNUErtVErlKKVOKKV+0MU2y5RStUqpI86vxwcmXSGGj835m7E5bNw7xYTO0KYqyM6AuV+E0DGexzPB1uxiQgP9uWl6vK9TGTHc+RxkA36itT6klIoEDiqldmitT3ba7lOt9e3mpyjE8KO1ZuPpjSyIX0DamDTPAx5+FWzNcLXvp5gDsNkdbD9ewvIZ8YQFSXOLt/R6hq61LtZaH3I+rgdyAN/fuk2IIWx/yX4K6wrN6Qx12OHAn417tiTO9jyeCfaeraSqsU1Gt3hZn9rQlVKpwAJgXxerr1FKHVVKvaeUmtXN69cqpbKUUlnl5eV9TlaI4SIjL4OooChuSbnF82Cnd0BN4aAZqgiwLbuY8CB/lk2T5hZvcrugK6UigE3AD7XWdZ1WHwJStNbzgD8Ab3cVQ2u9XmudrrVOj4uL62/OQgxplc2VfFT0kXmdofvXQ+RYmL7a81gmsNodbD9Rws0zEwgJ9Pd1OiOKWwVdKRWIUcw3aK3f7Lxea12ntW5wPn4XCFRKxZqaqRDDxDtn3sHmsJnT3FKRD2c+MmYk8h8cV2Luya+gpsnK7XPH+jqVEcedUS4KeBHI0Vr/ppttEp3boZRa5IxbaWaiQgwHDu1gY95GFsYvZNLoSZ4HPPAC+AXCVQ97HsskW7OLiQwO4Iapck7nbe50Py8FHgSOKaWOOJf9M5AMoLV+DrgX+LZSygY0A/dprfUA5CvEkLaveB/n68/zyPxHPA/WWg9HXoNZn4eIwdFW3WZz8P6JEm6ZlUBwgDS3eFuvBV1rvRvo8Q75WutngGfMSkqI4SojL4NRwaPM6QzNfgNa62DxtzyPZZJPT5dT32KT0S0+IleKCuElFc0V7CzayZrJawj2D/YsmNbGfVvGLoBxV5mToAm2ZhczKjSQ69Jk0IMvSEEXwkvezn8bm7aZc5vcgk+h/JQxVHEQTDEH0GK1s+NkKStmJRAUIKXFF+SoC+EFDu1gU94m0hPSmTTKhM7Qfc9DaDTMutvzWCb5e145Da02VsvoFp+Rgi6EF3xm+YwLDRfMGapYcx5y3zVGtgSaMI7dJNuyixkTFsi1k2N8ncqIJQVdCC/IyMtgdPBobk4x4T7lWX8xvqd/zfNYJmlus/NhTikrZycS6C9lxVfkyAsxwMqbytl5fid3Tr6TIP8gz4JZW+DQyzBtFYxONidBE+zKLaOpzS4XE/mYFHQhBtjb+W9j13ZzOkNPvAVNlYPqvi1gjG6JCQ9i8cRoX6cyoklBF2IAObSDTac3sShxEamjUj0LpjXsfx5ip8HEG0zJzwyNrTY+OlXKbXMSCZDmFp+Soy/EAMq0ZHKx4aI5naEXD4LlsDHF3CAZqgjw8akyWqwOVs+R5hZfk4IuxADKyM0gOiSa5cnLPQ+2fz0ERcK8+zyPZaKt2RbiIoNZJM0tPicFXYgBUvnqev5e8BF3vplH4OQpsGFD/4O9/Cc4/AZ8WgnT5ngWy0RlL73GzuwLrN61Ef9JEwdNXiOVFHQhBsKGDWS++C/Y/RUr9tVAYSGsXdu/grdhA7z+/0Bp2NfqWSwzbdjAk1tOgtY8fHDL4MlrBJOCLsRAWLeOPVODiK6zMaOoxVjW1ATr1vU91pOPwnwFJ2xQrT2LZaIP//hXtk25hu9nvs7EasugyWskk4IuxABwnC9i7+wIlpxowM/1RtJFRX0PllQGwQp2t3Zc3p9YJmlotfH4/HuZWl7I2n2d5rzxYV4jnUzHLcQAOLUolaqoAJYea+i4IrmPFwO1NcI1IZDXBmUOz2KZ6L8/yKU4MoaN7/yKIIet40of5jXSyRm6EAMg85FVAFxzwqWgh4XB00/3LdChVyBEQ1anYYr9iWWSo+dreDmzgAdirFxV0+ls3Id5CSnoQgyIzPgmphJH3OhxxpjxlBRYvx7uv9/9ILY2yPwDpCyFX6w3YvQ3lkmsdgc/f/MYsRHB/Oz7dxh5DIK8hEGaXIQwWZO1icNlh3lw1oNQ8OP+Bzr2N6i7CHf8HqbcPCgK5V92nyOnuI7nHlhIVEigkdMgyEsY5AxdCJPtL9mPzWHj2nHX9j+Iww67fwuJcyHNhIuSTHC+qonffpjHLTMTWDEr0dfpiC5IQRfCZJmWTEL8Q1gQv6D/QXK2QGU+XP/jQXGZv9aadW8fx18pnrpzFmoQ5CSuJAVdCJNlWjJJT0zv/7yhWsPu30BMGsxYY25y/bT5qIVP8sr52YppJI0K9XU6ohtS0IUw0YX6CxTWFbJ07NL+BznzERQfhaU/AD9/85Lrp+rGNp7acpJ5E0bz4DWpvk5H9EA6RYUwUaYlE8Cz9vNPfwtR42Du4LgJ17+/m0Nts5VX756Dv580tQxmvZ6hK6UmKKV2KqVylFInlFI/6GIbpZT6vVIqXymVrZRaODDpCjG4ZVoySQxPZGLUxP4FKNoHhbvhmu9CgIezG5kg80wFGQcv8M0bJjEjKcrX6YheuNPkYgN+orWeASwBvqOUmtlpm9uAKc6vtcCzpmYpxBBgdVjZV7yPpWOX9r/TcPdvIDTamADax1qsdta9dZzk6DB+sHyKr9MRbui1oGuti7XWh5yP64EcYFynze4EXtGGz4DRSqkk07MVYhA7Vn6MBmsD147tZ3NL6QnI2w6L/xGCws1Nrh/+uDOfcxWNPP352YQE+r4tX/SuT52iSqlUYAGwr9OqccB5l+cXuLLoo5Raq5TKUkpllZeX9y1TIQa5PZY9+Ck/Fict7l+A3b+FoAhjRiIfyyut59ldZ7h7wTiunxLn63SEm9wu6EqpCGAT8EOtdV3n1V28RF+xQOv1Wut0rXV6XJy8ScTwsteyl9mxsxkVPKrvL646C8c3QfpXIcy3M/84HJpH3zxGZEgA61bP8Gkuom/cKuhKqUCMYr5Ba/1mF5tcACa4PB8PWDxPT4ihoaalhuMVx/s/XHHP78EvAJZ8x9zE+uG1/UUcLKxm3eqZxET0cyy98Al3Rrko4EUgR2v9m2422ww85BztsgSo1VoXm5inEIPaZ8WfodH9az+vL4EjG2D+/RDl266n0roWfvXeKa6dHMM9C69oNRWDnDvj0JcCDwLHlFJHnMv+GUgG0Fo/B7wLrALygSbgq+anKsTgtceyh8igSGbHzu77i/c+Aw4bLP2++Yn10RObT9Bmd/Dvn58jl/cPQb0WdK31brpuI3fdRgO+/6wohA9orcm0ZLIkaQkBfn28Vq+5GrL+F2bdDdGTBiZBN+04Wcp7x0v42YpppMb6fpSN6Du59F8ID52pOUNZU1n/mlv2vwBtDXDdj8xPrA8aWm08/s5xpiVE8s3rffuPRfSfXPovhIf2WPYA9L1DtK0RPnsWpq6ExH401Zjov97PpaSuhWe+vJCgADnPG6rkNyeEhzItmUwcNZGkiD52aB58GZqr4DoPJsEwwZHzNby8t4AHl6RwVcoYn+YiPCMFXQgPtNhaOFh6sO9n57Y2ozM0ZSkk9/NCJBNY7Q4effMY8ZHB/GzFNJ/lIcwhBV0IDxwqPUSrvZVrxl7Ttxdmv2FML3e9b8/OX3ROKffkmtlEhgT6NBfhOSnoQnhgj2UPgX6BpCeku/8i1+nlJvtuernCykb+58M8bp2ZwMrZMqXccCAFXQgPZFoyWZiwkLDAMPdflLMZqs74dHo5rTWPvX2cAD8/nrxzlk9yEOaTgi5EP5U0lpBfk9+39nOt4VPfTy/3zhELn56ukCnlhhkp6EL0017LXoC+jT/P/whKsmHpD302vVx1YxtPbT3J/AmjeWBJik9yEANDCroQ/ZRpySQ2NJapY6a6/6Ldv3FOL/elgUusF0+/m0Nds5X/kCnlhh0p6EL0g91hZ2/xXq4de6379zwp+gwK98C13/PZ9HKZ+RVsPHiBtTKl3LAkBV2IfjhZeZLa1tq+Nbd86pxebuFDA5dYD1qsdv75rWOkxITxfZlSbliSgi5EP2RaMgHcH39echxOvw9Lvu2z6eWe+Tifgsomnr5rjkwpN0xJQReiHzItmcyInkF0iJuzC/l4erncknqe+/sZ7l44juumxPokBzHwpKAL0Uf1bfUcLT/K0nFuDlesPAMn3oT0r0Go9++VYkwpl01kSACPrZ7p9f0L75GCLkQf7S/ej13b3W8/z/w9+AXCNb6ZMmDD/iIOFdXw2OqZRIf7pjNWeIcUdCH6KNOSSVhAGBkje0QAAB2zSURBVPPj5ve+cV0xHHkN5n8ZIr1/eX1JbQv/+d4plqbFcLdMKTfsSUEXog+01uyx7GFR4iIC/d24mdWl6eV+MPDJdaF9Srmn75Ip5UYCKehC9EFRfREXGy5y7Tg3mluaqozp5WbfA9ETBz65Tj44UcL2EyV8f/kUmVJuhJCCLkQf7LnYh9mJ9r8A1kafTC9X32Ll8XdOMC0hkrU3yJRyI4VMQSdEH2RaMhkfMZ7kqOSeN2xtgH3PwtTbIMH7dzP87w/yKK1v4U8PLCTQX87bRgr5TQvhJqvdyv6S/e6Nbjn0MjRX+2QCi8NF1by8t4CHlqSwMFmmlBtJpKAL4aYj5UdotjX33n5ua4XMZyDlOpiwyDvJObVPKZcQGcJPZUq5EafXgq6U+otSqkwpdbyb9cuUUrVKqSPOr8fNT1MI39tzcQ8BKoDFib3MAXr0dai3wPXebzv/86fnOFVSz5N3zpIp5UYgd9rQXwKeAV7pYZtPtda3m5KREINUpiWTuXFziQiK6H4jhx32/A6S5nl9ern2KeVWzEpgxSyZUm4k6vUMXWv9CVDlhVyEGLQqmyvJqcrpvf385DvG9HLXeXd6Oa016946TqC/H0+ume21/YrBxaw29GuUUkeVUu8ppbrt0ldKrVVKZSmlssrLy03atRADb2+xMTtRj/dv6TC93B1eyszw9pGL7M6v4J9WTiNxVIhX9y0GDzMK+iEgRWs9D/gD8HZ3G2qt12ut07XW6XFxcSbsWgjvyLyYyejg0cyIntH9RvkfQukxY9y5F6eXq2ps41+35rAgeTT3L5Yp5UYyjwu61rpOa93gfPwuEKiUkvtzimHDoR1kWjK5Juka/Hsq1J86p5eb80XvJQc8vU2mlBMGjwu6UipROW8SoZRa5IxZ6WlcIQaL09WnqWyp7Hm4YuFeKMr0+vRye/Ir2HToAt/63CSmJ8qUciNdr6NclFJ/BZYBsUqpC8AvgEAArfVzwL3At5VSNqAZuE9rrQcsYyG8bI/FuNz/mqQeZifa/RsIi/Hq9HItVjvr3jpGakwY37tJppQTbhR0rfU/9LL+GYxhjUIMS5kXM0kbnUZCeELXGxRnw+kP4MbHvDq93B8+Pk1BZRMbvrFYppQTgFwpKkSPmqxNHCo71PPNuC5NL/cNr+V1qqSO5/9+lnsWjmdpmnRZCYMUdCF6kFWahdVh7b79vPIMnHzbq9PLGVPKHSMqNJB1q3sYdSNGHCnoQvQg05JJsH8wC+MXdr3Bnt95fXq5DfsKOVxUw2OrZ8iUcqIDKehC9GDPxT2kJ6QTEtDFxTp1Fjj6V1hwv9emlyupbeFX23O5Li2Wzy+QKeVER1LQheiGpcFCQV1B95f77/2jMb3ctd/3Wk6/2Hwcq93B05+fLVPKiStIQReiG5mWTKCby/0vTS93r9eml3v/RAnvnyjlBzdPISVGppQTV5KCLkQ3Mi2ZxIfFM2lUF1O47V/v1enlsgqqePyd40xPjOSb18uUcqJrUtCF6MqGDZw5sJ05n+ajJk6EDRsur/u/l+C9X8JpGyxe1XGdyUpqW/jB64e597m9qJIS/uuXXyNw8qQB3acYumROUSE627AB1q6l9L9TWFJlhcJiWLv28vrffxdW+8NnrVBYeHnd/feblkKL1c6Lu8/xx5352Kw2vrf/Tb69+zXCrK3GBgOwTzH0SUEXorN162hwtNAY6k9CldVY1tQE69YBGm4BKuxw1t5xnQnFVWvNjpOl/Nu2HIqqmlgxK4HHfvktJpw81HFDE/cphg8p6B5qsdr5+IVNbN6Tx76YySS21pGWGs/kq2eRFh/B5LgIJsaGD7pLs7XWVLZUUlBbQGFdIQV1BRSc3E1BWS6V4ZBQD+MTpzF++hLGR45nQuQExkeMZ2zE2K6H8A0nRUWUJRrju+NrrB2WM84PxoXDu81XvMZT+WX1PLnlJJ+ermBKfASvfn0x102JhYcPd5vnoGK3Qd1FqCmCmkLn9yLIPQAVZwA71AbB7Jvg5vth7HwYneLViUCGOyno/WC1O9h9uoLNRy18cPQCjY5w4saksPzMPirDRnPUL4CttXlojDeqUjBhTBiT48IvFfnJ8RGkxUUwZoAvDGmyNl0u2HXO4u0s4g3WhkvbBeFPsqWZNEszS2pslEYHcsF2gn26kGasHWLGh8YzPnK88RUxvsPj2NDYoT+cLjmZ0vAKABKqbR2Wc30jtLbCUesVr+mv2mYrv/vwNK/sLSA0yJ9f3DGTB5akEOjvdzl2YWGXeXqVw26MvW8v1K5Fu6YQai+Ctru8QEHAaDhXBZVW0ECihor3IeMDY5OQ0cZ0fWPnQ9J843H0JCny/SQF3U12h2b/uSo2H7Xw3vFiapqsjAoN5I7TmazZv43F54/jrx2Xtm+ZlMa53QfJL2vgTHkDZ8obyS9rIPNMJa22y9tFhweRFhfB5PjwDoV+3OhQ/Ny8t7XNYeNiw8VLxdq1cJc1l3XYNik8idSoVG6fdDupo1JJjUolJSqFpLnX4V9wZdHQKSlU5RzkQsMFLtQ7v5yP95fsZ0vjFjSXb64Z4h/CuIhxVxb8iPGMixxHaEBoXw+99z39NGUv/hjgcpNLWBg8+TM49xhkaWhz2T4sDJ5+us+7sTs0GVnn+fX7uVQ1tXHf1cn89NapxEQEX5EPa9cazSwe7rNHDgc0lBgFurrQpWg7H9deMMbdu4pMMs6yJyyBOckwJgVGJxtfUeMhbSoU1nd8jT8wbxw8/xRYjkDxEdj7J3A4j3XwKEia61Lk5xtF3k/GcPRG+epOt+np6TorK8sn+3aX1pqjF2rZctTC1mwLpXWthAX5c8vMBO6YO5YbpsYRFBRgTD3WmVLGH0gnDofmYk0z+eUNnGkv9mWN5Jc3UNV4uUoEB/gxKS7i0ln9pNhw4ka3oQPLsTQWXT7rri3gQv0FbPryH1pUUNSlYt1esFNHpZIcmdx9c4mfX59+jnZt9jYsDZYuC/75+vM02Zo6bB8bGnvFWX3797iwOPzU4PijXf9/3+EPjk84sPYkIUkTjOI5thD+/p+Q8gt48ndGk0dysrGuj23ZBwureGLzSY5drCU9ZQxPrJnF7HGjun/Bhg1Gm7kH+0RraCjteFZd7XKWXXse7G0dXxOR4CzQLoV6TIrxfNR4CAjuel/t3H1f2dqg7KRR3C1HoPgolJ4Au7MTODgKEud2PJuPSRuRRV4pdVBrnd7lOinoV8orrWfzEQtbsi0UVjYR5O/H56bFsWbeWJbPiCcsyOWDTWpq1x+HU1KgoKBP+61qbONkSRlZF09zsiKfwtpCKlov0EwpfkHlKP/WS9sqHUBkQCJJYclMHj2ReQlpzIxLIyUqhTEh/bhJlIk/RzutNTWtNR2K/IUGo9BfqL9ASWNJh7P7IL8gxkWO61DkXQt/WGBYv/Loj3/77N/YXrCd3fftNhbYWuG3s41icn9Gv+OW1Lbwy/dyePuIhcSoEB5dNZ0188aa00ylNTRWOAt0weVC3V60a8+DraXja8JiO55Vj05xKd4TINDDT1SevK/sVijLMYp7e6EvPX75ZwiKgMQ5RnFvL/KxU7w6/Z8v9FTQpcnFqaiyiS3ZFrYctXCqpB4/BUvTYvnOjWmsmJXIqNDArl/Yj4/Drk0k52rPUVhX2GUTifJTJMUmMSEymdGBiwjSibQ1R1NTN4aL5cGcq2jiotVBFvAGEB1ezuS4piva6d1qvhmAj/VKKcaEjGFMyBjmxM25Yr3VbsXSaLnizP5CwwUOlR2i0drYYfvokOgOhb69o3Z85Hjiw+JNPbsvbSwlPiz+8oITb0NjGSz+Vr/idRiG6NB898Y0vr1sMuHBffgT1Bqaq6G6oJt27CKwdvxERGi0UZwTZsK0lS7FOsUo2AN9/3ZP3lf+gUbTS9Jc4EFjmd0GFbmXm2qKj8Khl2Hfs8b6wLDLRb79bD52GviPjFI3os/Qy+pa2JJdzJajFo6crzHyShnDmvljuW12EnGRvXycbNfFx2H95S9fGkXi2qZdUGdSEwldNd80XmrGqXRpvgm1tbKkMJtlNee48csrSf5qN3OWmPGx3iRaa2pbazsUedfCX9xYjMOlzyK0TfPwe+WsPRpK4FOe5/3FLV8kOjSa525+zljwwk3QUgff2d+nj/laaz7MKePftp2ksLKJW2cm8NjqmSTHuPlpQ2ujaL3xOJR+AiGd/l5DRnUs0h3OtpMhONLtXAfMQL+vHHaoyLvcVFN8xJh0pP2EICAUEmcbBb79bD5uuvEPYwiSJhcXNU1tvHe8hM1HLHx2rhKtYWZSFGvmj+X2uUmMH9O3j/VN1qYrCnb7GXeHUSR+QSRHJXco2O0FfHTIaLN/TKob2ziz4U3OvPAqJ0eP55OJCzkXbdydb1KQnc9dPZkbp8WzaGL0oBtS6Q6rw0pJQwnn33mZC68+w760ID5YNIq08y3862uVzF73B4+KxrI3lrFswjKeuPYJuJAFf14Ot/0aFq/t9bXtXIchpsVH8Is7ZnL9lDj3XtxYCcf+Boc3QOkxsGnIscFFO9Q4oCUInvofeOib/fsBhzuH3bhX/aU2eWeRb3N20PoHQ8KsjqNr4md6dT7Y/hrxBb2x1caOk6VsPmrhk7xybA7NpNhw7pg3ljvmjSUtPqLH11sdViwNlg5NJAV1BRTWFnZsIkGRFJ50qWCnRKUYRXtUKolhiT3PGD8QOrVfFoxOYtekq9g563o+S55Dq81BaKA/10yO4cZpcSybFs+EaO+1U5vC5Wf8+7xInnp4LBWjA3g408ojzx7t15h5q93KwlcX8u153+aR+Y/Apm9A7nb4SY5bZ7x1LcYwxJczjWGIP7p5Kg9e4zIMsTsOO5z5GA7/H5x61xj1MXYBbMqFT0qgU/O3J/0bI5LDAVVnnUX+sPNsPhtaa431/kFGUR87//LZfMKs3jt+vWxEFvQWq51dueVsybbwUU4pLVYHSaNCuGPeWNbMG8ussVEdOqLaL7Tp3KbdVRPJqOBRl8+0nQU7JSql1yYSr+thhEFLq5W9ZyvZdaqMXXnlFFYabZyT4sK5cVo8y6bFsWhiNMEBg/zsvdPPWB/qx39/KZFNy6JJiUrhqWufYmFCN5NTdMPSYGHFphU8cc0T3JO01OgMvfobcNsve3ydw6HJOGgMQ6xsbOO+qyfw01unXTkMsbPKM3D4VTj6OtRbjMmm595n3Gc9YVa/RyAJNzgcUH2uY8dr8VFoMZpg8QuE+Bkuo2sWGL+TQN/9nY+Ygm6zO8g8U8nmoxbeP15CfauNmPAgVs1JYs38sVyVPIYWe3Ofm0g6nG0PUBPJgOjDCINzFY3sdBb3z85W0uY8e1+aFsPnpsWzbGrc4Dx77+Zn/GzZJJ747hQsDRbum34fP1z4Q7dHyRwuO8xD7z3En5b/ietP74a//xK+dwhiJnf7GtdhiFeljOGJO2YxZ3wPwxBbG+DkO0YhL8oE5Qdpt8CCB2Dqyo4f/QdgBJLogdZGZ7Nrx6vlCDRXGeuVv7PIz798Np8wG4K88/cxrAu6w6E5WFTN5iMW3j1WTGVjG5HBiutm+jMrtZXwsCrONxS53UQyMWoiKaNSfNNEYjbnTaauGGGwfn2P7cvNbXb2nq1gV245u3LLKaoyXp8WH8GyqUbTzNUTxwyOs/cefsamL36e3x/+Pa/lvMbYiLH84ppfcM3Ya3oNub1gOz/7+8/YuOp1pr10V49DFUvrWvjle6d46/BFEqKC+edVM7ofhqg1nN9nNKmceBvaGoyx1AseMM7Io5L6/DPKvVy8RGtj2Gd7cW8/m28yrihG+UPctI6jaxLnDMgoIo8KulLqL8DtQJnWenYX6xXwO2AV0AR8RWt9qPN2nXlS0LXWHL9Yy9+O5PB+bjbVVguBIRXERdfhH1RJVVsx9m6aSCaOmkhKVMrgbCIZCB6OMNBac7ai0Vncy9h3too2u4OwIH+unRzLsmlxLJsW1+fOZFP18jMeLjvM43sep6CugLun3M1P0n9CVFBUt+FeOfEKv876Nbvn/JRRm78PD2yCtJs7bNNqM4YhPvNxPja75ps3TOSRZWldD0OsK4bs142z8cp8Y/z0rLtgwYMwYbF7l7kPohFIwklr41YIrh2vliPG8FYwPnXFTu04uiZxjscjjzwt6DcADcAr3RT0VcD3MAr6YuB3WuvFvSXVr4L+yCO8kLeXP901BmtYXYcLbYZFE8kQ0NRmY++ZSnbllrMzt4wL1cZNqqbER7BsWhw3TosnPTWaoIDBdQVfi62FZ48+y0snXiI2JJbHljzGjck3drntrw/8mjdy3+BAcySqpQ6+c+DSUEWtNR/llPGvzmGIt8xM4LHVM66cQcjWBnnbjSKevwO0A5KvNc7GZ94JwT13xIshrK64Y1NN8RGoL3auVFCrYE8TlCX16x+zRxcWaa0/UUql9rDJnRjFXgOfKaVGK6WStNbFPbym7x55BJ59lpir0whujWVefgDX5RYzc/4NpKz7r+HRRDIEhAUFsHxGAstnJKC15kx5I7tyy9iVW87LmYW88Ok5woP8uTYt9lLn6tjRvr9/S0hACD+66kfcmnIr/5L5L3x/5/e5beJtPLro0SuurC1rKiMhaBQqP8sYqugs5vllDfzr1pP8Pa+cyXHhvPK1RdwwtdMwxNITxlDD7NehqdK418nSH8L8+yE2zVs/rvClqCTja9ptl5fVl8Jf/wf+9geIdYBVD8i99N1qQ3cW9K3dnKFvBX6ptd7tfP4R8P+01j2efvf5DD0gAOz2K5f7+4PNduVy4XWNrcbZ+05ngb9YY5y9T02I4MZp8XxuWhzpKb4/e7farfz52J9Zf2w9UUFRPLr4UVakrLjU7v3Qew/hX5HP/54vgp/kUKdD+P2Hp3kps4DQQH9+eMtUHnIdhthcA8c3GmfjlsPGyIjpq4wmlUk3jpirFEUvTOrc9rhTtJeCvg34j04F/Z+01ge72HYtsBYgOTn5qsKufrjuk+h+nY86dkX3jLP3BnaeKmdXXhn7z1VhtWsiggNYmhbDsmnxXD8llvjIEAL9lU9uuZtXncfjex7nROUJbppwE48teYy4sDhWZtzCvPJz/DL1bjLivsd/vn+KysY2vpQ+gZ+umEZsRLAxZvzcJ3BkA+RsMe4vkjDbaFKZ80UIj/H6zyMGOZOGnw50QX8e2KW1/qvzeS6wrLcmFzlDH1kaWm1k5lewK6+cv7ucvQP4O+yEBvgREhZCaJAfoYH+hAb6ExLoT2iQ/+XnLo9Dg5zrA/0JC7py29Agv0vrQ4P8CQnw7/J+NjaHjVc2/Ig/tu4kuM3Bjz6y8u93hPJgbS15/Ce7igNZldTAD+dDsuOCcYn56X3QbDFuA9uqIP4G+NJTRueX3MdbdMcLZ+hmfBbcDHxXKfU6Rqdorent52C0NT37bNfLxaAXERzArbMSuXVWIvrVDZz+41Psi0ujLjiclsBgmkPDaVp+Ky0pk2i22o2vNjvVjW1YLj130GK109Rmw9GPD2XBAX4d/0EE+hNaW0XoqbFMD7iFwrmHeGpNFaCJsTl4vH4dz4WUQzWwE2PUQkAM5JRCmdW4DD/XBsEfQfyX4P75Jh81Max44b727oxy+SuwDIgFSoFfAIEAWuvnnMMWnwFWYgxb/Gpv7efQ/1EurF9vnKn7+xsH509/6lsM4XsenqlorbHaNc1WOy3Owt/UZu/wvP2fwhXPLz120Nxmp2XnLprs0BwQTHNgEE1JucSN+4B/LmxgcW4FAZHJ8NN/N4afRU+CKdPlIh/RfyYMPx3WFxaJIWgwXcreXS6uli+HDz/seXu5DF94SU8FfXANFhYjQ3dzYXp7jkx39/nRR71v74vchehECrrwvqefNtoOXQ3EHJn9zaWv2/sqdyE6kYIuvO/++42+kJQUo6kiJcV39yVxzaWv2/s6dyE6kTZ0IdrdfHPH5pV2rm3oQviYtKEL4Y4PPzSKtysp5mIIkWuShXAlxVsMYXKGLoQQw4QUdCGEGCakoAshxDAhBV0IIYYJKehCCDFM+GwculKqHOjDDdE7iAUqTEzHLIM1Lxi8uUlefSN59c1wzCtFax3X1QqfFXRPKKWyuhtY70uDNS8YvLlJXn0jefXNSMtLmlyEEGKYkIIuhBDDxFAt6Ot9nUA3BmteMHhzk7z6RvLqmxGV15BsQxdCCHGloXqGLoQQohMp6EIIMUwM2oKulPqCUuqEUsqhlOp2eI9SaqVSKlcpla+U+rnL8olKqX1KqdNKqTeUUkEm5RWtlNrhjLtDKTWmi21uVEodcflqUUrd5Vz3klLqnMs6U6aKdycv53Z2l31vdlnuy+M1Xym11/n7zlZKfcllnanHq7v3i8v6YOfPn+88Hqku6x51Ls9VSq3wJI9+5PVjpdRJ5/H5SCmV4rKuy9+pl/L6ilKq3GX/33BZ97Dz935aKfWwl/P6rUtOeUqpGpd1A3m8/qKUKlNKHe9mvVJK/d6Zd7ZSaqHLOs+Pl9Z6UH4BM4BpwC4gvZtt/IEzwCQgCDgKzHSu+xtwn/Pxc8C3TcrrP4GfOx//HPhVL9tHA1VAmPP5S8C9A3C83MoLaOhmuc+OFzAVmOJ8PBYoBkabfbx6er+4bPMI8Jzz8X3AG87HM53bBwMTnXH8vZjXjS7voW+359XT79RLeX0FeKaL10YDZ53fxzgfj/FWXp22/x7wl4E+Xs7YNwALgePdrF8FvAcoYAmwz8zjNWjP0LXWOVrr3F42WwTka63Paq3bgNeBO5VSCrgJ2Ojc7mXgLpNSu9MZz9249wLvaa2bTNp/d/qa1yW+Pl5a6zyt9WnnYwtQBnR5JZyHuny/9JDvRmC58/jcCbyutW7VWp8D8p3xvJKX1nqny3voM2C8Sfv2KK8erAB2aK2rtNbVwA5gpY/y+gfgrybtu0da608wTuC6cyfwijZ8BoxWSiVh0vEatAXdTeOA8y7PLziXxQA1Wmtbp+VmSNBaFwM4v8f3sv19XPlmetr5ceu3SqlgL+cVopTKUkp91t4MxCA6XkqpRRhnXWdcFpt1vLp7v3S5jfN41GIcH3deO5B5ufo6xlleu65+p97M6x7n72ejUmpCH187kHnhbJqaCHzssnigjpc7usvdlOPl0xmLlFIfAoldrFqntX7HnRBdLNM9LPc4L3djOOMkAXOA910WPwqUYBSt9cD/A57yYl7JWmuLUmoS8LFS6hhQ18V2vjpe/wc8rLV2OBf3+3h1tYsulnX+OQfkPdULt2MrpR4A0oHPuSy+4neqtT7T1esHIK8twF+11q1KqX/E+HRzk5uvHci82t0HbNRa212WDdTxcseAvr98WtC11jd7GOICMMHl+XjAgnHTm9FKqQDnWVb7co/zUkqVKqWStNbFzgJU1kOoLwJvaa2tLrGLnQ9blVL/C/zUm3k5mzTQWp9VSu0CFgCb8PHxUkpFAduAx5wfRdtj9/t4daG790tX21xQSgUAozA+Qrvz2oHMC6XUzRj/JD+ntW5tX97N79SMAtVrXlrrSpenLwC/cnntsk6v3WVCTm7l5eI+4DuuCwbweLmju9xNOV5DvcnlADBFGSM0gjB+eZu10cuwE6P9GuBhwJ0zfndsdsZzJ+4VbXfOotbebn0X0GVv+EDkpZQa095koZSKBZYCJ319vJy/u7cw2hYzOq0z83h1+X7pId97gY+dx2czcJ8yRsFMBKYA+z3IpU95KaUWAM8Da7TWZS7Lu/ydejGvJJena4Ac5+P3gVud+Y0BbqXjJ9UBzcuZ2zSMDsa9LssG8ni5YzPwkHO0yxKg1nnSYs7xGqjeXk+/gM9j/NdqBUqB953LxwLvumy3CsjD+A+7zmX5JIw/uHwgAwg2Ka8Y4CPgtPN7tHN5OvBnl+1SgYuAX6fXfwwcwyhMrwIR3soLuNa576PO718fDMcLeACwAkdcvuYPxPHq6v2C0YSzxvk4xPnz5zuPxySX165zvi4XuM3k93tveX3o/DtoPz6be/udeimv/wBOOPe/E5ju8tqvOY9jPvBVb+blfP4E8MtOrxvo4/VXjFFaVoz69XXgH4F/dK5XwB+deR/DZQSfGcdLLv0XQohhYqg3uQghhHCSgi6EEMOEFHQhhBgmpKALIcQwIQVdCCGGCSnoQggxTEhBF0KIYeL/A4rcXHkSvVxQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numx = x.numpy()\n",
    "numy = y.numpy()\n",
    "\n",
    "predict = model(x)\n",
    "predict = predict.data.numpy()\n",
    "plt.plot(numx, numy, 'ro', label='original data')\n",
    "plt.plot(x, predict, label='fitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Classification   \n",
    "二分类算法- __Logistic回归__   \n",
    "\n",
    "## 3.3.3 Logistic distribution   \n",
    "Supposed that X是连续的随机变量，服从Logistic分布是指X的积累分布函数如下：\n",
    "$$ F(x) = P(X <= x) = \\frac{1}{1 + e^{-(x-u)/r}}$$\n",
    "u 影响中心对称点的位置, r越小，中心点附近的增长速度越快。  \n",
    "\n",
    "Sigmoid函数，Logistic分布函数中r=1，u=0的形式： \n",
    "$$ P(x) = \\frac{1}{1 + e^{-x}}$$ \n",
    "\n",
    "## 3.3.4 two-class Logistic regression  \n",
    "对于二分类问题，Logistic回归的目标：希望找到一个区分度好的决策边界。  \n",
    "假设样本的部分点A：$$ h_{w}(x) = \\sum {w_i * x_i + b} > 0$$ \n",
    "   另外的样本点B：$$ h_{w}(x) = \\sum {w_i * x_i + b} < 0$$ \n",
    "   属于A的，可以判定它的类别为1；属于B的，可以判定它的类别是0.  \n",
    "   $$P(Y=0|x) = \\frac{1}{1 + e^{w*x +b}}$$\n",
    "   $$P(Y=1|x) = \\frac{e^{w*x + b}}{1 + e^{w*x +b}}$$\n",
    "   \n",
    "### logit function:\n",
    "$$logit(p) = log(\\frac{p}{1-p})$$\n",
    "$$log(\\frac{P(Y=1|x)}{P(Y=0|x)}) = w*x + b  $$\n",
    "$$log(\\frac{P(Y=1|x)}{1- P(Y=1|x)}) = w*x + b $$\n",
    "在Logistic回归模型中，输出Y=1的对数几率 是 输入x的线性函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hengshi/Documents/IFT725_myUnderstanding/Pytorch_tutorial/data.txt'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, 'data.txt')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34.62365962451697,78.0246928153624,0', '30.28671076822607,43.89499752400101,0', '35.84740876993872,72.90219802708364,0', '60.18259938620976,86.30855209546826,1']\n",
      "[['34.62365962451697', '78.0246928153624', '0'], ['30.28671076822607', '43.89499752400101', '0'], ['35.84740876993872', '72.90219802708364', '0'], ['60.18259938620976', '86.30855209546826', '1']]\n",
      "[(34.62365962451697, 78.0246928153624, 0), (30.28671076822607, 43.89499752400101, 0), (35.84740876993872, 72.90219802708364, 0), (60.18259938620976, 86.30855209546826, 1)]\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'r') as f:\n",
    "    datalist = f.readlines()\n",
    "    data = [i.split('\\n')[0] for i in datalist]\n",
    "    print(data[:4])\n",
    "    data = [i.split(',') for i in data]\n",
    "    print(data[:4])\n",
    "    data = [(float(i[0]), float(i[1]), int(i[2])) for i in data]\n",
    "    print(data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x126bfed50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the data\n",
    "import matplotlib.pyplot as plt\n",
    "x0 = list(filter(lambda x: x[-1] == 0, data))\n",
    "x1 = list(filter(lambda x: x[-1] == 1, data))\n",
    "# Plot the points of x0 in red\n",
    "x0_a = [i[0] for i in x0]\n",
    "x0_b = [i[1] for i in x0]\n",
    "plt.plot(x0_a, x0_b, 'ro', label='x0')\n",
    "# plot the points of x1 in blue\n",
    "x1_a = [i[0] for i in x1]\n",
    "x1_b = [i[1] for i in x1]\n",
    "plt.plot(x1_a, x1_b, 'bo', label='x1')\n",
    "plt.legend(loc='best') # set the position of legend and show the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to look for the line to separate the two classes. \n",
    "### w0* x + w1*y + b = 0. To look for the w, b\n",
    "## 定义Logistic回归模型，二分类的损失函数 和 优化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to look for the line to separate the two classes. \n",
    "# y = w * x + b. To look for the w, b\n",
    "class Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Logistic, self).__init__()\n",
    "        self.Linear = nn.Linear(2, 1)\n",
    "        self.sm = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Linear(x)\n",
    "        out = self.sm(out)\n",
    "        return out\n",
    "    \n",
    "model = Logistic()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3863, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3161, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2834, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2645, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2521, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "np_data = np.array(data, dtype='float32') # 转换成 numpy array\n",
    "x_data = torch.from_numpy(np_data[:, 0:2]) # 转换成 Tensor, 大小是 [100, 2]\n",
    "y_data = torch.from_numpy(np_data[:, -1]).unsqueeze(1) # 转换成 Tensor，大小是 [100, 1]\n",
    "\n",
    "for epoch in range(50000):\n",
    "  \n",
    "    x = Variable(x_data)\n",
    "    y = Variable(y_data)\n",
    "    \n",
    "    predict = model(x)\n",
    "    loss = criterion(predict, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%10000 == 0:\n",
    "        print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the parameters of the model\n",
    "### model.linear.weight[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0994) tensor(0.0933) tensor([-11.7589])\n"
     ]
    }
   ],
   "source": [
    "w0, w1 = model.Linear.weight[0]\n",
    "w0 = w0.data\n",
    "w1 = w1.data\n",
    "b = model.Linear.bias.data[0]  ## tensor(11.7589) tensor([-11.7589])\n",
    "print(w0, w1, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x126b34f50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotx = np.arange(20, 100, 0.1)\n",
    "ploty = (-w0*plotx - b) / w1\n",
    "plt.plot(plotx, ploty)\n",
    "x0 = list(filter(lambda x: x[-1] == 0, data))\n",
    "x1 = list(filter(lambda x: x[-1] == 1, data))\n",
    "# Plot the points of x0 in red\n",
    "x0_a = [i[0] for i in x0]\n",
    "x0_b = [i[1] for i in x0]\n",
    "plt.plot(x0_a, x0_b, 'ro', label='x0')\n",
    "# plot the points of x1 in blue\n",
    "x1_a = [i[0] for i in x1]\n",
    "x1_b = [i[1] for i in x1]\n",
    "plt.plot(x1_a, x1_b, 'bo', label='x1')\n",
    "plt.legend(loc='best') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
