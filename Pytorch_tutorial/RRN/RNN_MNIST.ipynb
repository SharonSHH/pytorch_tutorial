{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RNN to classify pictures （MNIST）\n",
    "\n",
    "### MNIST图片大小28*28，那么图片可以看作是长为28的序列，序列中的每个元素的特征维度是28.  \n",
    "这样，将一张图片变成一个序列；考虑到RNN对previous信息的记忆功能，我们将图片从左往右输入网络的时候，网络可以记忆前面观察的东西。 虽然，将一张图片切割成了28份，但网络仍能记住前面的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 20\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_loader.dataset), len(test_loader.dataset))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Recurrent Network 模型\n",
    "class Rnn(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_layer, n_class):\n",
    "        super(Rnn, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(in_dim, hidden_dim, n_layer, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0 = Variable(torch.zeros(self.n_layer, x.size(1),\n",
    "        #   self.hidden_dim)).cuda()\n",
    "        # c0 = Variable(torch.zeros(self.n_layer, x.size(1),\n",
    "        #   self.hidden_dim)).cuda()\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.classifier(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model = Rnn(28, 128, 2, 10)  # 图片大小是28x28\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "print(use_gpu)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "# 定义loss和optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.18</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n",
      "[1/20] Loss: 0.801607, Acc: 0.725233\n",
      "[1/20] Loss: 0.501206, Acc: 0.831850\n",
      "Finish 1 epoch, Loss: 0.501206, Acc: 0.831850\n",
      "epoch 2\n",
      "**********\n",
      "[2/20] Loss: 0.138276, Acc: 0.957300\n",
      "[2/20] Loss: 0.119588, Acc: 0.963233\n",
      "Finish 2 epoch, Loss: 0.119588, Acc: 0.963233\n",
      "epoch 3\n",
      "**********\n",
      "[3/20] Loss: 0.082405, Acc: 0.973700\n",
      "[3/20] Loss: 0.078249, Acc: 0.975800\n",
      "Finish 3 epoch, Loss: 0.078249, Acc: 0.975800\n",
      "epoch 4\n",
      "**********\n",
      "[4/20] Loss: 0.057571, Acc: 0.982333\n",
      "[4/20] Loss: 0.060694, Acc: 0.981500\n",
      "Finish 4 epoch, Loss: 0.060694, Acc: 0.981500\n",
      "epoch 5\n",
      "**********\n",
      "[5/20] Loss: 0.051527, Acc: 0.985100\n",
      "[5/20] Loss: 0.048425, Acc: 0.985667\n",
      "Finish 5 epoch, Loss: 0.048425, Acc: 0.985667\n",
      "epoch 6\n",
      "**********\n",
      "[6/20] Loss: 0.042926, Acc: 0.986133\n",
      "[6/20] Loss: 0.040002, Acc: 0.987567\n",
      "Finish 6 epoch, Loss: 0.040002, Acc: 0.987567\n",
      "epoch 7\n",
      "**********\n",
      "[7/20] Loss: 0.034835, Acc: 0.989667\n",
      "[7/20] Loss: 0.035165, Acc: 0.989417\n",
      "Finish 7 epoch, Loss: 0.035165, Acc: 0.989417\n",
      "epoch 8\n",
      "**********\n",
      "[8/20] Loss: 0.027199, Acc: 0.991700\n",
      "[8/20] Loss: 0.030460, Acc: 0.990417\n",
      "Finish 8 epoch, Loss: 0.030460, Acc: 0.990417\n",
      "epoch 9\n",
      "**********\n",
      "[9/20] Loss: 0.026391, Acc: 0.992033\n",
      "[9/20] Loss: 0.027728, Acc: 0.991467\n",
      "Finish 9 epoch, Loss: 0.027728, Acc: 0.991467\n",
      "epoch 10\n",
      "**********\n",
      "[10/20] Loss: 0.024557, Acc: 0.991967\n",
      "[10/20] Loss: 0.025290, Acc: 0.992000\n",
      "Finish 10 epoch, Loss: 0.025290, Acc: 0.992000\n",
      "epoch 11\n",
      "**********\n",
      "[11/20] Loss: 0.020839, Acc: 0.993233\n",
      "[11/20] Loss: 0.021515, Acc: 0.993350\n",
      "Finish 11 epoch, Loss: 0.021515, Acc: 0.993350\n",
      "epoch 12\n",
      "**********\n",
      "[12/20] Loss: 0.020020, Acc: 0.993467\n",
      "[12/20] Loss: 0.021215, Acc: 0.993083\n",
      "Finish 12 epoch, Loss: 0.021215, Acc: 0.993083\n",
      "epoch 13\n",
      "**********\n",
      "[13/20] Loss: 0.017054, Acc: 0.994700\n",
      "[13/20] Loss: 0.017792, Acc: 0.994233\n",
      "Finish 13 epoch, Loss: 0.017792, Acc: 0.994233\n",
      "epoch 14\n",
      "**********\n",
      "[14/20] Loss: 0.016121, Acc: 0.994767\n",
      "[14/20] Loss: 0.016102, Acc: 0.994750\n",
      "Finish 14 epoch, Loss: 0.016102, Acc: 0.994750\n",
      "epoch 15\n",
      "**********\n",
      "[15/20] Loss: 0.016151, Acc: 0.995133\n",
      "[15/20] Loss: 0.014682, Acc: 0.995333\n",
      "Finish 15 epoch, Loss: 0.014682, Acc: 0.995333\n",
      "epoch 16\n",
      "**********\n",
      "[16/20] Loss: 0.012421, Acc: 0.995800\n",
      "[16/20] Loss: 0.016354, Acc: 0.994917\n",
      "Finish 16 epoch, Loss: 0.016354, Acc: 0.994917\n",
      "epoch 17\n",
      "**********\n",
      "[17/20] Loss: 0.010131, Acc: 0.996867\n",
      "[17/20] Loss: 0.012316, Acc: 0.996117\n",
      "Finish 17 epoch, Loss: 0.012316, Acc: 0.996117\n",
      "epoch 18\n",
      "**********\n",
      "[18/20] Loss: 0.007931, Acc: 0.997567\n",
      "[18/20] Loss: 0.010550, Acc: 0.996817\n",
      "Finish 18 epoch, Loss: 0.010550, Acc: 0.996817\n",
      "epoch 19\n",
      "**********\n",
      "[19/20] Loss: 0.010369, Acc: 0.996533\n",
      "[19/20] Loss: 0.014134, Acc: 0.995683\n",
      "Finish 19 epoch, Loss: 0.014134, Acc: 0.995683\n",
      "epoch 20\n",
      "**********\n",
      "[20/20] Loss: 0.009992, Acc: 0.996867\n",
      "[20/20] Loss: 0.010721, Acc: 0.996683\n",
      "Finish 20 epoch, Loss: 0.010721, Acc: 0.996683\n"
     ]
    }
   ],
   "source": [
    "# %%pixie_debugger\n",
    "# 开始训练\n",
    "for epoch in range(num_epoches):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        b, c, h, w = img.size()\n",
    "        assert c == 1, 'channel must be 1'\n",
    "        img = img.squeeze(1)                     # ?squeeze(1)\n",
    "        # img = img.view(b*h, w)\n",
    "        # img = torch.transpose(img, 1, 0)\n",
    "        # img = img.contiguous().view(w, b, -1)\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data * label.size(0)  # loss.data[0]\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.data # [0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                running_acc / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n",
    "            train_dataset))))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/USHERBROOKE/shih3801/project_725/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/local/USHERBROOKE/shih3801/project_725/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.045104, Acc: 0.988700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(num_epoches): 不用加循环，模型已经训练好了，所以，值是一样的\n",
    "model.eval()\n",
    "eval_loss = 0.\n",
    "eval_acc = 0.\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    b, c, h, w = img.size()\n",
    "    assert c == 1, 'channel must be 1'\n",
    "    img = img.squeeze(1)\n",
    "    # img = img.view(b*h, w)\n",
    "    # img = torch.transpose(img, 1, 0)\n",
    "    # img = img.contiguous().view(w, b, h)\n",
    "    if use_gpu:\n",
    "        img = Variable(img, volatile=True).cuda()\n",
    "        label = Variable(label, volatile=True).cuda()\n",
    "    else:\n",
    "        img = Variable(img, volatile=True)\n",
    "        label = Variable(label, volatile=True)\n",
    "    out = model(img)\n",
    "    loss = criterion(out, label)\n",
    "    eval_loss += loss.data * label.size(0)\n",
    "    _, pred = torch.max(out, 1)\n",
    "    num_correct = (pred == label).sum()\n",
    "    eval_acc += num_correct.data  # [0]\n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "    test_dataset)), eval_acc / (len(test_dataset))))\n",
    "print()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './rnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
